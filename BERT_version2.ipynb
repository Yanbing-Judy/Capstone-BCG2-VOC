{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b5f36b4",
   "metadata": {},
   "source": [
    "reference: https://github.com/649453932/Bert-Chinese-Text-Classification-Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe59d76",
   "metadata": {},
   "source": [
    "# Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb0d20ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/vivianruan/Downloads'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90b6cb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content</th>\n",
       "      <th>subject</th>\n",
       "      <th>sentiment_value</th>\n",
       "      <th>sentiment_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13149</td>\n",
       "      <td>因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>影响</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2288</td>\n",
       "      <td>四驱价格貌似挺高的，高的可以看齐XC60了，看实车前脸有点违和感。不过大众的车应该不会差。</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>高</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1652</td>\n",
       "      <td>斯柯达要说质量，似乎比大众要好一点，价格也低一些，用料完全一样。我听说过野帝，但没听说过你说...</td>\n",
       "      <td>价格</td>\n",
       "      <td>1</td>\n",
       "      <td>低</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8865</td>\n",
       "      <td>这玩意都是给有钱任性又不懂车的土豪用的，这价格换一次我妹夫EP020可以换三锅了</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>有钱任性</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11784</td>\n",
       "      <td>17价格忒高，估计也就是14-15左右。</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>高</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12567</th>\n",
       "      <td>17392</td>\n",
       "      <td>全时四驱仅比一般SUV车强一点，肯定干不过Q5，XC60，连A4也干不过。水平对置仅体现在低...</td>\n",
       "      <td>动力</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12568</th>\n",
       "      <td>9780</td>\n",
       "      <td>哈哈，终于看到有人开始厌烦前置雷达的声音了，这个亲，那个声音来自哪里？</td>\n",
       "      <td>配置</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12569</th>\n",
       "      <td>1079</td>\n",
       "      <td>请教一下，变速箱油，差速器油，火花塞，分别多久更换。</td>\n",
       "      <td>动力</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12570</th>\n",
       "      <td>16766</td>\n",
       "      <td>求购二手１４款ＸＴ的后刹车总成。（已网购到手了）</td>\n",
       "      <td>安全性</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12571</th>\n",
       "      <td>9651</td>\n",
       "      <td>是的，就是奔全时四驱买的车。</td>\n",
       "      <td>操控</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       content_id                                            content subject  \\\n",
       "0           13149           因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。      价格   \n",
       "1            2288      四驱价格貌似挺高的，高的可以看齐XC60了，看实车前脸有点违和感。不过大众的车应该不会差。      价格   \n",
       "2            1652  斯柯达要说质量，似乎比大众要好一点，价格也低一些，用料完全一样。我听说过野帝，但没听说过你说...      价格   \n",
       "3            8865           这玩意都是给有钱任性又不懂车的土豪用的，这价格换一次我妹夫EP020可以换三锅了      价格   \n",
       "4           11784                            17价格忒高，估计也就是14-15左右。         价格   \n",
       "...           ...                                                ...     ...   \n",
       "12567       17392  全时四驱仅比一般SUV车强一点，肯定干不过Q5，XC60，连A4也干不过。水平对置仅体现在低...      动力   \n",
       "12568        9780                哈哈，终于看到有人开始厌烦前置雷达的声音了，这个亲，那个声音来自哪里？      配置   \n",
       "12569        1079                         请教一下，变速箱油，差速器油，火花塞，分别多久更换。      动力   \n",
       "12570       16766                           求购二手１４款ＸＴ的后刹车总成。（已网购到手了）     安全性   \n",
       "12571        9651                                     是的，就是奔全时四驱买的车。      操控   \n",
       "\n",
       "       sentiment_value sentiment_word  \n",
       "0                    0             影响  \n",
       "1                   -1              高  \n",
       "2                    1              低  \n",
       "3                   -1           有钱任性  \n",
       "4                   -1              高  \n",
       "...                ...            ...  \n",
       "12567                0            NaN  \n",
       "12568               -1            NaN  \n",
       "12569                0            NaN  \n",
       "12570                0            NaN  \n",
       "12571                1            NaN  \n",
       "\n",
       "[12572 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_2.csv')\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d772dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {\n",
    "    \"动力\": 0,\n",
    "    \"价格\": 1,\n",
    "    \"油耗\": 2,\n",
    "    \"操控\": 3,\n",
    "    \"舒适性\": 4,\n",
    "    \"配置\": 5,\n",
    "    \"安全性\": 6,\n",
    "    \"内饰\": 7,\n",
    "    \"外观\": 8,\n",
    "    \"空间\": 9\n",
    "}\n",
    "df = df.replace({\"subject\":label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "134adfdb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3454\n",
       "1    1634\n",
       "2    1379\n",
       "3    1302\n",
       "4    1182\n",
       "5    1075\n",
       "6     736\n",
       "7     669\n",
       "8     606\n",
       "9     535\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d309c3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>四驱价格貌似挺高的，高的可以看齐XC60了，看实车前脸有点违和感。不过大众的车应该不会差。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>斯柯达要说质量，似乎比大众要好一点，价格也低一些，用料完全一样。我听说过野帝，但没听说过你说...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>这玩意都是给有钱任性又不懂车的土豪用的，这价格换一次我妹夫EP020可以换三锅了</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17价格忒高，估计也就是14-15左右。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12567</th>\n",
       "      <td>全时四驱仅比一般SUV车强一点，肯定干不过Q5，XC60，连A4也干不过。水平对置仅体现在低...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12568</th>\n",
       "      <td>哈哈，终于看到有人开始厌烦前置雷达的声音了，这个亲，那个声音来自哪里？</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12569</th>\n",
       "      <td>请教一下，变速箱油，差速器油，火花塞，分别多久更换。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12570</th>\n",
       "      <td>求购二手１４款ＸＴ的后刹车总成。（已网购到手了）</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12571</th>\n",
       "      <td>是的，就是奔全时四驱买的车。</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  subject\n",
       "0               因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。        1\n",
       "1          四驱价格貌似挺高的，高的可以看齐XC60了，看实车前脸有点违和感。不过大众的车应该不会差。        1\n",
       "2      斯柯达要说质量，似乎比大众要好一点，价格也低一些，用料完全一样。我听说过野帝，但没听说过你说...        1\n",
       "3               这玩意都是给有钱任性又不懂车的土豪用的，这价格换一次我妹夫EP020可以换三锅了        1\n",
       "4                                17价格忒高，估计也就是14-15左右。           1\n",
       "...                                                  ...      ...\n",
       "12567  全时四驱仅比一般SUV车强一点，肯定干不过Q5，XC60，连A4也干不过。水平对置仅体现在低...        0\n",
       "12568                哈哈，终于看到有人开始厌烦前置雷达的声音了，这个亲，那个声音来自哪里？        5\n",
       "12569                         请教一下，变速箱油，差速器油，火花塞，分别多久更换。        0\n",
       "12570                           求购二手１４款ＸＴ的后刹车总成。（已网购到手了）        6\n",
       "12571                                     是的，就是奔全时四驱买的车。        3\n",
       "\n",
       "[12572 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "df_new = df_new[[\"content\",\"subject\"]]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e1b1e52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7543 2514 2515\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "df_train, df_val, df_test = np.split(df_new.sample(frac=1, random_state=111),\n",
    "                                     [int(.6*len(df_new)), int(.8*len(df_new))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "110ccac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('/Users/vivianruan/Downloads/THUCNews/data_2/train.txt', \n",
    "                header=None, index=None, sep='\\t', mode='a')\n",
    "df_val.to_csv('/Users/vivianruan/Downloads/THUCNews/data_2/test.txt', \n",
    "                header=None, index=None, sep='\\t', mode='a')\n",
    "df_test.to_csv('/Users/vivianruan/Downloads/THUCNews/data_2/dev.txt', \n",
    "                header=None, index=None, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df4eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import pytorch_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e4fe5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-pretrained-bert in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (0.6.2)\n",
      "Requirement already satisfied: regex in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from pytorch-pretrained-bert) (2022.7.9)\n",
      "Requirement already satisfied: boto3 in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from pytorch-pretrained-bert) (1.24.28)\n",
      "Requirement already satisfied: torch>=0.4.1 in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from pytorch-pretrained-bert) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from pytorch-pretrained-bert) (4.64.1)\n",
      "Requirement already satisfied: numpy in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from pytorch-pretrained-bert) (1.21.5)\n",
      "Requirement already satisfied: requests in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from pytorch-pretrained-bert) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.3.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from boto3->pytorch-pretrained-bert) (1.27.28)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from boto3->pytorch-pretrained-bert) (0.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from requests->pytorch-pretrained-bert) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from requests->pytorch-pretrained-bert) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from requests->pytorch-pretrained-bert) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from requests->pytorch-pretrained-bert) (2.0.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.28->boto3->pytorch-pretrained-bert) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/vivianruan/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.28->boto3->pytorch-pretrained-bert) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dba8ec",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e4569e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "PAD, CLS = '[PAD]', '[CLS]'  # padding符号, bert中综合信息符号\n",
    "\n",
    "\n",
    "def build_dataset(config):\n",
    "\n",
    "    def load_dataset(path, pad_size=32): \n",
    "        contents = []\n",
    "        with open(path, 'r', encoding='UTF-8') as f:\n",
    "            for line in tqdm(f):\n",
    "                lin = line.strip()\n",
    "                if not lin:\n",
    "                    continue\n",
    "                content, label = lin.split('\\t')\n",
    "                token = config.tokenizer.tokenize(content)\n",
    "                token = [CLS] + token\n",
    "                seq_len = len(token)\n",
    "                mask = []\n",
    "                token_ids = config.tokenizer.convert_tokens_to_ids(token)\n",
    "\n",
    "                if pad_size:\n",
    "                    if len(token) < pad_size:\n",
    "                        mask = [1] * len(token_ids) + [0] * (pad_size - len(token))\n",
    "                        token_ids += ([0] * (pad_size - len(token)))\n",
    "                    else:\n",
    "                        mask = [1] * pad_size\n",
    "                        token_ids = token_ids[:pad_size]\n",
    "                        seq_len = pad_size\n",
    "                contents.append((token_ids, int(label), seq_len, mask))\n",
    "        return contents\n",
    "    train = load_dataset(config.train_path, config.pad_size)\n",
    "    dev = load_dataset(config.dev_path, config.pad_size)\n",
    "    test = load_dataset(config.test_path, config.pad_size)\n",
    "    return train, dev, test\n",
    "\n",
    "\n",
    "class DatasetIterater(object):\n",
    "    def __init__(self, batches, batch_size, device):\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = batches\n",
    "        self.n_batches = len(batches) // batch_size\n",
    "        self.residue = False  # 记录batch数量是否为整数\n",
    "        if len(batches) % self.n_batches != 0:\n",
    "            self.residue = True\n",
    "        self.index = 0\n",
    "        self.device = device\n",
    "\n",
    "    def _to_tensor(self, datas):\n",
    "        x = torch.LongTensor([_[0] for _ in datas]).to(self.device)\n",
    "        y = torch.LongTensor([_[1] for _ in datas]).to(self.device)\n",
    "\n",
    "        # pad前的长度(超过pad_size的设为pad_size)\n",
    "        seq_len = torch.LongTensor([_[2] for _ in datas]).to(self.device)\n",
    "        mask = torch.LongTensor([_[3] for _ in datas]).to(self.device)\n",
    "        return (x, seq_len, mask), y\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.residue and self.index == self.n_batches:\n",
    "            batches = self.batches[self.index * self.batch_size: len(self.batches)]\n",
    "            self.index += 1\n",
    "            batches = self._to_tensor(batches)\n",
    "            return batches\n",
    "\n",
    "        elif self.index >= self.n_batches:\n",
    "            self.index = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            batches = self.batches[self.index * self.batch_size: (self.index + 1) * self.batch_size]\n",
    "            self.index += 1\n",
    "            batches = self._to_tensor(batches)\n",
    "            return batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.residue:\n",
    "            return self.n_batches + 1\n",
    "        else:\n",
    "            return self.n_batches\n",
    "\n",
    "\n",
    "def build_iterator(dataset, config):\n",
    "    iter = DatasetIterater(dataset, config.batch_size, config.device)\n",
    "    return iter\n",
    "\n",
    "\n",
    "def get_time_dif(start_time):\n",
    "    \"\"\"获取已使用时间\"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    return timedelta(seconds=int(round(time_dif)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd76ae4",
   "metadata": {},
   "source": [
    "# BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e59848f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from pytorch_pretrained_bert import BertModel, BertTokenizer\n",
    "from pytorch_pretrained_bert import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "class Config(object):\n",
    "\n",
    "    \"\"\"配置参数\"\"\"\n",
    "    def __init__(self, dataset):\n",
    "        self.model_name = 'bert'\n",
    "        self.train_path = dataset + '/data_2/train.txt'                                # 训练集\n",
    "        self.dev_path = dataset + '/data_2/dev.txt'                                    # 验证集\n",
    "        self.test_path = dataset + '/data_2/test.txt'                                  # 测试集\n",
    "        self.class_list = [x.strip() for x in open(\n",
    "            dataset + '/data_2/class.txt').readlines()]                                # 类别名单\n",
    "        self.save_path = dataset + '/saved_dict_2/' + self.model_name + '.ckpt'        # 模型训练结果\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # 设备\n",
    "\n",
    "        self.require_improvement = 1000                                 # 若超过1000batch效果还没提升，则提前结束训练\n",
    "        self.num_classes = len(self.class_list)                         # 类别数\n",
    "        self.num_epochs = 3                                             # epoch数\n",
    "        self.batch_size = 128                                           # mini-batch大小\n",
    "        self.pad_size = 32                                              # 每句话处理成的长度(短填长切)\n",
    "        self.learning_rate = 5e-5                                       # 学习率\n",
    "        self.bert_path = './bert_pretrain'\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.bert_path)\n",
    "        self.hidden_size = 768\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(config.bert_path)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.fc = nn.Linear(config.hidden_size, config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        context = x[0]  # 输入的句子\n",
    "        mask = x[2]  # 对padding部分进行mask，和句子一个size，padding部分用0表示，如：[1, 1, 1, 1, 0, 0]\n",
    "        _, pooled = self.bert(context, attention_mask=mask, output_all_encoded_layers=False)\n",
    "        out = self.fc(pooled)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0a4e54",
   "metadata": {},
   "source": [
    "# train eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b645c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from pytorch_pretrained_bert import BertAdam\n",
    "\n",
    "\n",
    "# 权重初始化，默认xavier\n",
    "def init_network(model, method='xavier', exclude='embedding', seed=123):\n",
    "    for name, w in model.named_parameters():\n",
    "        if exclude not in name:\n",
    "            if len(w.size()) < 2:\n",
    "                continue\n",
    "            if 'weight' in name:\n",
    "                if method == 'xavier':\n",
    "                    nn.init.xavier_normal_(w)\n",
    "                elif method == 'kaiming':\n",
    "                    nn.init.kaiming_normal_(w)\n",
    "                else:\n",
    "                    nn.init.normal_(w)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(w, 0)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "def train(config, model, train_iter, dev_iter, test_iter):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=config.learning_rate,\n",
    "                         warmup=0.05,\n",
    "                         t_total=len(train_iter) * config.num_epochs)\n",
    "    total_batch = 0  # 记录进行到多少batch\n",
    "    dev_best_loss = float('inf')\n",
    "    last_improve = 0  # 记录上次验证集loss下降的batch数\n",
    "    flag = False  # 记录是否很久没有效果提升\n",
    "    model.train()\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print('Epoch [{}/{}]'.format(epoch + 1, config.num_epochs))\n",
    "        for i, (trains, labels) in enumerate(train_iter):\n",
    "            outputs = model(trains)\n",
    "            model.zero_grad()\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if total_batch % 100 == 0:\n",
    "                # 每多少轮输出在训练集和验证集上的效果\n",
    "                true = labels.data.cpu()\n",
    "                predic = torch.max(outputs.data, 1)[1].cpu()\n",
    "                train_acc = metrics.accuracy_score(true, predic)\n",
    "                dev_acc, dev_loss = evaluate(config, model, dev_iter)\n",
    "                if dev_loss < dev_best_loss:\n",
    "                    dev_best_loss = dev_loss\n",
    "                    torch.save(model.state_dict(), config.save_path)\n",
    "                    improve = '*'\n",
    "                    last_improve = total_batch\n",
    "                else:\n",
    "                    improve = ''\n",
    "                time_dif = get_time_dif(start_time)\n",
    "                msg = 'Iter: {0:>6},  Train Loss: {1:>5.2},  Train Acc: {2:>6.2%},  Val Loss: {3:>5.2},  Val Acc: {4:>6.2%},  Time: {5} {6}'\n",
    "                print(msg.format(total_batch, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve))\n",
    "                model.train()\n",
    "            total_batch += 1\n",
    "            if total_batch - last_improve > config.require_improvement:\n",
    "                # 验证集loss超过1000batch没下降，结束训练\n",
    "                print(\"No optimization for a long time, auto-stopping...\")\n",
    "                flag = True\n",
    "                break\n",
    "        if flag:\n",
    "            break\n",
    "    test(config, model, test_iter)\n",
    "\n",
    "\n",
    "def test(config, model, test_iter):\n",
    "    # test\n",
    "    model.load_state_dict(torch.load(config.save_path))\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    test_acc, test_loss, test_report, test_confusion = evaluate(config, model, test_iter, test=True)\n",
    "    msg = 'Test Loss: {0:>5.2},  Test Acc: {1:>6.2%}'\n",
    "    print(msg.format(test_loss, test_acc))\n",
    "    print(\"Precision, Recall and F1-Score...\")\n",
    "    print(test_report)\n",
    "    print(\"Confusion Matrix...\")\n",
    "    print(test_confusion)\n",
    "    time_dif = get_time_dif(start_time)\n",
    "    print(\"Time usage:\", time_dif)\n",
    "\n",
    "\n",
    "def evaluate(config, model, data_iter, test=False):\n",
    "    model.eval()\n",
    "    loss_total = 0\n",
    "    predict_all = np.array([], dtype=int)\n",
    "    labels_all = np.array([], dtype=int)\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in data_iter:\n",
    "            outputs = model(texts)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss_total += loss\n",
    "            labels = labels.data.cpu().numpy()\n",
    "            predic = torch.max(outputs.data, 1)[1].cpu().numpy()\n",
    "            labels_all = np.append(labels_all, labels)\n",
    "            predict_all = np.append(predict_all, predic)\n",
    "\n",
    "    acc = metrics.accuracy_score(labels_all, predict_all)\n",
    "    if test:\n",
    "        report = metrics.classification_report(labels_all, predict_all, target_names=config.class_list, digits=4)\n",
    "        confusion = metrics.confusion_matrix(labels_all, predict_all)\n",
    "        return acc, loss_total / len(data_iter), report, confusion\n",
    "    return acc, loss_total / len(data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b589d7",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "28ba1019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15086it [00:01, 7575.46it/s]\n",
      "2515it [00:00, 7578.83it/s]\n",
      "2514it [00:00, 7614.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time usage: 0:00:03\n",
      "Epoch [1/3]\n",
      "Iter:      0,  Train Loss:   2.3,  Train Acc: 12.50%,  Val Loss:   2.3,  Val Acc:  8.19%,  Time: 0:00:32 *\n",
      "Iter:    100,  Train Loss:  0.81,  Train Acc: 78.12%,  Val Loss:  0.98,  Val Acc: 69.30%,  Time: 0:14:29 *\n",
      "Epoch [2/3]\n",
      "Iter:    200,  Train Loss:  0.83,  Train Acc: 69.53%,  Val Loss:   1.0,  Val Acc: 67.99%,  Time: 0:26:55 \n",
      "Epoch [3/3]\n",
      "Iter:    300,  Train Loss:  0.53,  Train Acc: 81.25%,  Val Loss:   1.1,  Val Acc: 65.45%,  Time: 0:39:05 \n",
      "Test Loss:  0.99,  Test Acc: 70.05%\n",
      "Precision, Recall and F1-Score...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          动力     0.7457    0.7599    0.7527       683\n",
      "          价格     0.7861    0.7982    0.7921       327\n",
      "          油耗     0.7389    0.7918    0.7644       293\n",
      "          操控     0.7338    0.3864    0.5062       264\n",
      "         舒适性     0.5805    0.6982    0.6339       222\n",
      "          配置     0.6873    0.7807    0.7310       228\n",
      "         安全性     0.5660    0.6977    0.6250       129\n",
      "          内饰     0.6241    0.5845    0.6036       142\n",
      "          外观     0.7258    0.6767    0.7004       133\n",
      "          空间     0.5604    0.5484    0.5543        93\n",
      "\n",
      "    accuracy                         0.7005      2514\n",
      "   macro avg     0.6749    0.6722    0.6664      2514\n",
      "weighted avg     0.7050    0.7005    0.6958      2514\n",
      "\n",
      "Confusion Matrix...\n",
      "[[519  21  44  10  34  17  13   6  11   8]\n",
      " [ 23 261   7   3   9  15   4   0   2   3]\n",
      " [ 27   7 232   2   9   9   2   2   1   2]\n",
      " [ 47  11  10 102  31  16  32   9   2   4]\n",
      " [ 23   4   8   3 155   6   4   9   1   9]\n",
      " [ 12   6   3   4   5 178   5   4   5   6]\n",
      " [ 10   6   2   3   9   1  90   5   2   1]\n",
      " [ 14   4   4   3   8   8   4  83   9   5]\n",
      " [  5   8   3   2   4   3   4  12  90   2]\n",
      " [ 16   4   1   7   3   6   1   3   1  51]]\n",
      "Time usage: 0:00:23\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from importlib import import_module\n",
    "import argparse\n",
    "\n",
    "#parser = argparse.ArgumentParser(description='Chinese Text Classification')\n",
    "#parser.add_argument('--model', type=str, required=True, help='choose a model: Bert, ERNIE')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "# args={\"model\": \"Bert\"}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = 'THUCNews'  # 数据集\n",
    "\n",
    "    #model_name = args.model  # bert\n",
    "    #x = import_module('models.' + model_name)\n",
    "    config = Config(dataset)\n",
    "    np.random.seed(1)\n",
    "    torch.manual_seed(1)\n",
    "    torch.cuda.manual_seed_all(1)\n",
    "    torch.backends.cudnn.deterministic = True  # 保证每次结果一样\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Loading data...\")\n",
    "    train_data, dev_data, test_data = build_dataset(config)\n",
    "    train_iter = build_iterator(train_data, config)\n",
    "    dev_iter = build_iterator(dev_data, config)\n",
    "    test_iter = build_iterator(test_data, config)\n",
    "    time_dif = get_time_dif(start_time)\n",
    "    print(\"Time usage:\", time_dif)\n",
    "\n",
    "    # train\n",
    "    model = Model(config).to(config.device)\n",
    "    train(config, model, train_iter, dev_iter, test_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
